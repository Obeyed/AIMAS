\section{Results}
\label{sec:results}

%\emph{Benchmarks (test results) and possibly competition results.  Include explanations and analyses of your results. As mentioned under “Benchmarks and comparisons” below, it is usually a clear strength if you have some results to com- pare, e.g. two different versions of your client with different methods/features/parameters.  You could also compare the behaviour of your client on different individual levels that illustrate a certain point, e.g. similar levels resulting in large differences in the client’s behaviour.}

To showcase how efficient our goal prioritisation technique is and how we have improved upon it throughout the project, we present some test runs using the \texttt{SAOptimal} level.
In the following we will refer to our main goal prioritisation technique (\cref{methods:goal_ordering}) as the ``complex'' prioritisation, and use the term ``simple'' to mean a priotitisation that does not perform the final matrix computation as presented in \cref{methods:goal_ordering}.
The intuition is that goals placed in dead-ends or corners must be achieved before any goals that would otherwise block the path to the inner most goals.

We illustrate three runs on the same level; one with complex goal prioritisation (\cref{fig:complex_priority}, one with simple goal prioritisation (\cref{fig:simple priority}) and one without goal prioritisation whatsoever(\cref{fig:no priority}). 

% Example of cells
\begin{figure}[h!]
  \centering
  \begin{minipage}{.30\columnwidth}
    \centering
    \includegraphics[height=3cm]{graphics/no_priority_block.png}
    \caption{\label{fig:no priority}Arbi\-tra\-ry prioritisation.}
  \end{minipage}%
  \hspace{10pt}%
  \begin{minipage}{.30\columnwidth}
    \centering
    \includegraphics[height=3cm]{graphics/simple_priority_block.PNG}
    \caption{\label{fig:simple priority}Simple prioritisation.}
  \end{minipage}%
  \hspace{10pt}%
  \begin{minipage}{.30\columnwidth}
    \centering
    \includegraphics[height=3cm]{graphics/complex_priority.png}
    \caption{\label{fig:complex_priority}Comp\-lex prioritisation.}
  \end{minipage}
\end{figure}

The main difference between the complex and simple prioritisation is that the complex forces a specific order on goals which are grouped, as mentioned in \cref{methods:goal_ordering}.
As seen in figure \cref{fig:complex_priority}, the complex ordering results in the goals next to the level bounds, being fulfilled first. 
The lack of strict order in apparent in the example of the simple prioritisation as illustrated in \cref{fig:simple priority}. Here the agent chooses to place \textbf{R} before \textbf{S} and thus blocking the path of a goal.
With arbitrary prioritisation, as seen in \cref{fig:no priority}, even more goals are blocked by the fulfilment of others.
Our final client utilized the complex prioritisation method, and with this we managed to solve this level (\texttt{SAOptimal}) with 31 fewer moves than the simple prioritisation as presented in \cref{tab:SAOptimal_results}.

\begin{table}[h!]
  \centering
  \begin{tabular}{@{}ll@{}}
    \toprule
    Prioritisation technique & Actions \\
    \midrule
    None    & $>1000$ \\
    Simple  & $761$ \\
    Complex & $730$ \\
    \bottomrule
  \end{tabular}
  \caption{\label{tab:SAOptimal_results}No. actions performed on \texttt{SAOptimal} level with different prioritisation techniques.}
\end{table}

We found that a client with only arbitrary goal prioritisation, requires almost 50 \% more actions on this level than with some kind prioritisation technique.
This is due to the fact that many actions are wasted because the inner most goals are left open, and thus as the client wants to achieve them, all the previous boxes must be moved.

\subsection{Performance vs. Optimality}
\label{sec:performance vs. optimality}

We have developed a client with performance in mind.
The only technique we used to yield more intuitive solutions was to develop the goal prioritisation technique, so the client did not fill in goals arbitrarily.
From the course's competition presentation we found that, as an example, our client was beaten in \texttt{SAOptimal} with about 7 \% less actions performed.
However, our client solved the level approximately 700 times faster than the opponent.\footnote{\textbf{opponent}: $143,297$ ms with $680$ actions \& \textbf{our}: $209$ ms with actions $730$. (source: competition results)}

Note that we performed our tests on a laptop with Intel® Core™ i5 4210U Processor 2.7 GHz, 4GB DDR3L 1600 MHz SDRAM, with a Solid State Disk.

\subsection{Multi-agent vs. Single-agent levels}


